{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/haiduong/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/haiduong/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import keras\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from src.models.mlp import MLP\n",
    "from src.metrics import classification_metrics\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_DIR = str(Path.cwd().parent) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset\n",
    "There are two main functions in this part:\n",
    "- A function to read [train, test, dev] dataset file.\n",
    "- Another function to map label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ds_file(file_path: str):\n",
    "    ds = {\n",
    "        x: [] for x in [\"train\", \"test\", \"dev\"]\n",
    "    }\n",
    "\n",
    "    for key in ds.keys():\n",
    "        fp = os.path.join(file_path, f\"{key}.tsv\")\n",
    "\n",
    "        with open(fp, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "            for (i, line) in enumerate(lines):\n",
    "                line = line.strip()\n",
    "                items = line.split(\"\\t\")\n",
    "                text_a = items[0]\n",
    "                label = list(map(int, items[1].split(\",\")))\n",
    "                ds[key].append({\n",
    "                    \"text\": text_a, \n",
    "                    \"label\": label\n",
    "                })\n",
    "    return ds\n",
    "\n",
    "def read_label_file(file_path: str):\n",
    "    label_dict = {}\n",
    "\n",
    "    fp = os.path.join(file_path, f\"labels.txt\")\n",
    "    with open(fp, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            for i, line in enumerate(lines):\n",
    "                label_dict[i] = line.replace(\"\\n\", \"\")\n",
    "\n",
    "    return label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = PROJECT_DIR + \"/data/original\"\n",
    "\n",
    "ds = read_ds_file(path)\n",
    "label = read_label_file(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "In this part, i will create a function to handle the following preprocessing step:\n",
    "- Remove extra space\n",
    "- Word tokenization\n",
    "- Remove stop words\n",
    "- Lemmatize word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_space(ds: dict):\n",
    "    for _, value in ds.items():\n",
    "        for x in value:\n",
    "            x[\"text\"] = \" \".join(x[\"text\"].split())\n",
    "\n",
    "def tokenize_sequence(ds: dict):\n",
    "    for _, value in ds.items():\n",
    "        for x in value:\n",
    "            x[\"tokenized\"] = x[\"text\"].split(\" \")\n",
    "\n",
    "def lemmatize(ds: dict):\n",
    "    stopword = set(stopwords.words('english')) \n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "    for _, value in ds.items():\n",
    "        for x in value:\n",
    "            x[\"tokenized\"] = [lemmatizer.lemmatize(token) for token in x[\"tokenized\"] if token not in stopword]\n",
    "\n",
    "def preprocess_data(ds: dict):\n",
    "    remove_extra_space(ds)\n",
    "    tokenize_sequence(ds)\n",
    "    lemmatize(ds)\n",
    "\n",
    "    for _, value in ds.items():\n",
    "        for x in value:\n",
    "            x[\"preprocessed_text\"] = ' '.join(x[\"tokenized\"])\n",
    "\n",
    "preprocess_data(ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"My favourite food is anything I didn't have to cook myself.\",\n",
       "  'label': [27],\n",
       "  'tokenized': ['My', 'favourite', 'food', 'anything', 'I', 'cook', 'myself.'],\n",
       "  'preprocessed_text': 'My favourite food anything I cook myself.'},\n",
       " {'text': 'Now if he does off himself, everyone will think hes having a laugh screwing with people instead of actually dead',\n",
       "  'label': [27],\n",
       "  'tokenized': ['Now',\n",
       "   'himself,',\n",
       "   'everyone',\n",
       "   'think',\n",
       "   'he',\n",
       "   'laugh',\n",
       "   'screwing',\n",
       "   'people',\n",
       "   'instead',\n",
       "   'actually',\n",
       "   'dead'],\n",
       "  'preprocessed_text': 'Now himself, everyone think he laugh screwing people instead actually dead'},\n",
       " {'text': 'WHY THE FUCK IS BAYLESS ISOING',\n",
       "  'label': [2],\n",
       "  'tokenized': ['WHY', 'THE', 'FUCK', 'IS', 'BAYLESS', 'ISOING'],\n",
       "  'preprocessed_text': 'WHY THE FUCK IS BAYLESS ISOING'},\n",
       " {'text': 'To make her feel threatened',\n",
       "  'label': [14],\n",
       "  'tokenized': ['To', 'make', 'feel', 'threatened'],\n",
       "  'preprocessed_text': 'To make feel threatened'},\n",
       " {'text': 'Dirty Southern Wankers',\n",
       "  'label': [3],\n",
       "  'tokenized': ['Dirty', 'Southern', 'Wankers'],\n",
       "  'preprocessed_text': 'Dirty Southern Wankers'}]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data\n",
    "- This is the final step in data processing step where you have to vectorize tokenized words. There are two main parameters that you need to know: \n",
    "    - max_token: The maximum number of vocabulary\n",
    "    - output_mode: \"tf_idf\"\n",
    "    - sequence_length: The sample with the number of tokens smaller than this param will be padded with 0 to match the length. You can take the median or the mean from amount of tokens in all samples. For me, i often use the 95% percentile on the train dataset.\n",
    "- Transform label using MultiLabelBinarizer() from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetConfig:\n",
    "    MAX_TOKEN=20000\n",
    "    EMBEDDING_DIM = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_95_percentile(ds: list):\n",
    "    return np.percentile([len(x['tokenized']) for x in ds], 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(ds, output_mode):\n",
    "    prepared_data = {x: {} for x in [\"train\", \"test\", \"dev\"]}\n",
    "\n",
    "    sequence_length = find_95_percentile(ds[\"train\"])\n",
    "\n",
    "    if output_mode == \"int\":\n",
    "        vectorizer = keras.layers.TextVectorization(\n",
    "            max_tokens=DatasetConfig.MAX_TOKEN,\n",
    "            output_mode=output_mode,\n",
    "            output_sequence_length=int(sequence_length),\n",
    "            standardize=None\n",
    "        )\n",
    "    else:\n",
    "        vectorizer = keras.layers.TextVectorization(\n",
    "            max_tokens=DatasetConfig.MAX_TOKEN,\n",
    "            output_mode=output_mode,\n",
    "            standardize=None\n",
    "        )\n",
    "        \n",
    "    mlb = MultiLabelBinarizer()\n",
    "\n",
    "    for key, value in ds.items():\n",
    "        if key == \"train\":\n",
    "            vectorizer.adapt([x[\"preprocessed_text\"] for x in value])\n",
    "            vocab = vectorizer.get_vocabulary()\n",
    "\n",
    "            labels = mlb.fit_transform([x[\"label\"] for x in value])\n",
    "        else:\n",
    "            labels = mlb.transform([x[\"label\"] for x in value])\n",
    "\n",
    "        features = vectorizer([x[\"preprocessed_text\"] for x in value])  \n",
    "\n",
    "        prepared_data[key][\"features\"] = features\n",
    "        prepared_data[key][\"labels\"] = labels\n",
    "\n",
    "    return vocab, prepared_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, prepared_data = prepare_data(ds, output_mode=\"tf_idf\") # You can change the output_mode to either \"tf_idf\" or \"int\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model\n",
    "- Here are the list of experiment that I will perform in this notebook:\n",
    "    - Random Forest\n",
    "    - MLP\n",
    "    - 1D Convolution\n",
    "    - Feature extraction + Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = prepared_data[\"train\"][\"features\"], prepared_data[\"train\"][\"labels\"]\n",
    "X_test, y_test = prepared_data[\"test\"][\"features\"], prepared_data[\"test\"][\"labels\"]\n",
    "X_dev, y_dev = prepared_data[\"dev\"][\"features\"], prepared_data[\"dev\"][\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, int_prepared_data = prepare_data(ds, output_mode=\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_int, y_train_int = int_prepared_data[\"train\"][\"features\"], int_prepared_data[\"train\"][\"labels\"]\n",
    "X_test_int, y_test_int = int_prepared_data[\"test\"][\"features\"], int_prepared_data[\"test\"][\"labels\"]\n",
    "X_dev_int, y_dev_int = int_prepared_data[\"dev\"][\"features\"], int_prepared_data[\"dev\"][\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haiduong/miniforge3/envs/emotiai/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlp = MLP(sequence_length=len(X_train_int[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 19ms/step - binary_accuracy: 0.9543 - f1__macro: 0.0526 - loss: 0.1723 - precision: 0.3737 - recall: 0.0610 - val_binary_accuracy: 0.9642 - val_f1__macro: 0.1743 - val_loss: 0.1164 - val_precision: 0.6366 - val_recall: 0.3426\n",
      "Epoch 2/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 19ms/step - binary_accuracy: 0.9672 - f1__macro: 0.2477 - loss: 0.1051 - precision: 0.7223 - recall: 0.3571 - val_binary_accuracy: 0.9650 - val_f1__macro: 0.2914 - val_loss: 0.1098 - val_precision: 0.6715 - val_recall: 0.3274\n",
      "Epoch 3/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - binary_accuracy: 0.9716 - f1__macro: 0.3946 - loss: 0.0846 - precision: 0.7709 - recall: 0.4648 - val_binary_accuracy: 0.9644 - val_f1__macro: 0.3297 - val_loss: 0.1122 - val_precision: 0.6261 - val_recall: 0.3806\n",
      "Epoch 4/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - binary_accuracy: 0.9760 - f1__macro: 0.5018 - loss: 0.0696 - precision: 0.8092 - recall: 0.5631 - val_binary_accuracy: 0.9628 - val_f1__macro: 0.3390 - val_loss: 0.1198 - val_precision: 0.5927 - val_recall: 0.3652\n",
      "Epoch 5/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - binary_accuracy: 0.9798 - f1__macro: 0.5869 - loss: 0.0580 - precision: 0.8377 - recall: 0.6454 - val_binary_accuracy: 0.9612 - val_f1__macro: 0.3187 - val_loss: 0.1342 - val_precision: 0.5553 - val_recall: 0.3839\n",
      "Epoch 6/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 18ms/step - binary_accuracy: 0.9828 - f1__macro: 0.6393 - loss: 0.0491 - precision: 0.8574 - recall: 0.7077 - val_binary_accuracy: 0.9608 - val_f1__macro: 0.3141 - val_loss: 0.1509 - val_precision: 0.5485 - val_recall: 0.3693\n",
      "Epoch 7/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 19ms/step - binary_accuracy: 0.9847 - f1__macro: 0.6887 - loss: 0.0431 - precision: 0.8698 - recall: 0.7485 - val_binary_accuracy: 0.9594 - val_f1__macro: 0.3286 - val_loss: 0.1617 - val_precision: 0.5237 - val_recall: 0.3690\n",
      "Epoch 8/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - binary_accuracy: 0.9863 - f1__macro: 0.7262 - loss: 0.0386 - precision: 0.8816 - recall: 0.7802 - val_binary_accuracy: 0.9580 - val_f1__macro: 0.3008 - val_loss: 0.1816 - val_precision: 0.5004 - val_recall: 0.3918\n",
      "Epoch 9/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - binary_accuracy: 0.9877 - f1__macro: 0.7485 - loss: 0.0345 - precision: 0.8917 - recall: 0.8057 - val_binary_accuracy: 0.9570 - val_f1__macro: 0.3074 - val_loss: 0.1939 - val_precision: 0.4846 - val_recall: 0.3622\n",
      "Epoch 10/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - binary_accuracy: 0.9883 - f1__macro: 0.7614 - loss: 0.0322 - precision: 0.8959 - recall: 0.8175 - val_binary_accuracy: 0.9555 - val_f1__macro: 0.3026 - val_loss: 0.2116 - val_precision: 0.4633 - val_recall: 0.3719\n",
      "Epoch 11/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 19ms/step - binary_accuracy: 0.9894 - f1__macro: 0.7805 - loss: 0.0301 - precision: 0.9040 - recall: 0.8360 - val_binary_accuracy: 0.9525 - val_f1__macro: 0.2910 - val_loss: 0.2237 - val_precision: 0.4269 - val_recall: 0.3829\n",
      "Epoch 12/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - binary_accuracy: 0.9899 - f1__macro: 0.7870 - loss: 0.0283 - precision: 0.9065 - recall: 0.8468 - val_binary_accuracy: 0.9531 - val_f1__macro: 0.2963 - val_loss: 0.2372 - val_precision: 0.4334 - val_recall: 0.3843\n",
      "Epoch 13/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 18ms/step - binary_accuracy: 0.9903 - f1__macro: 0.7961 - loss: 0.0270 - precision: 0.9111 - recall: 0.8522 - val_binary_accuracy: 0.9530 - val_f1__macro: 0.2928 - val_loss: 0.2520 - val_precision: 0.4311 - val_recall: 0.3737\n",
      "Epoch 14/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 18ms/step - binary_accuracy: 0.9907 - f1__macro: 0.8078 - loss: 0.0258 - precision: 0.9132 - recall: 0.8601 - val_binary_accuracy: 0.9527 - val_f1__macro: 0.2836 - val_loss: 0.2628 - val_precision: 0.4284 - val_recall: 0.3746\n",
      "Epoch 15/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - binary_accuracy: 0.9913 - f1__macro: 0.8269 - loss: 0.0242 - precision: 0.9162 - recall: 0.8721 - val_binary_accuracy: 0.9509 - val_f1__macro: 0.2812 - val_loss: 0.2737 - val_precision: 0.4087 - val_recall: 0.3793\n",
      "Epoch 16/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 18ms/step - binary_accuracy: 0.9914 - f1__macro: 0.8217 - loss: 0.0238 - precision: 0.9184 - recall: 0.8719 - val_binary_accuracy: 0.9513 - val_f1__macro: 0.2751 - val_loss: 0.2888 - val_precision: 0.4118 - val_recall: 0.3712\n",
      "Epoch 17/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 19ms/step - binary_accuracy: 0.9917 - f1__macro: 0.8210 - loss: 0.0231 - precision: 0.9204 - recall: 0.8781 - val_binary_accuracy: 0.9518 - val_f1__macro: 0.2790 - val_loss: 0.3058 - val_precision: 0.4172 - val_recall: 0.3718\n",
      "Epoch 18/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 19ms/step - binary_accuracy: 0.9920 - f1__macro: 0.8277 - loss: 0.0222 - precision: 0.9238 - recall: 0.8822 - val_binary_accuracy: 0.9490 - val_f1__macro: 0.2758 - val_loss: 0.3107 - val_precision: 0.3866 - val_recall: 0.3652\n",
      "Epoch 19/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - binary_accuracy: 0.9923 - f1__macro: 0.8357 - loss: 0.0215 - precision: 0.9263 - recall: 0.8863 - val_binary_accuracy: 0.9501 - val_f1__macro: 0.2794 - val_loss: 0.3225 - val_precision: 0.3967 - val_recall: 0.3622\n",
      "Epoch 20/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - binary_accuracy: 0.9923 - f1__macro: 0.8324 - loss: 0.0211 - precision: 0.9262 - recall: 0.8885 - val_binary_accuracy: 0.9508 - val_f1__macro: 0.2685 - val_loss: 0.3372 - val_precision: 0.4054 - val_recall: 0.3699\n",
      "Epoch 21/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - binary_accuracy: 0.9926 - f1__macro: 0.8395 - loss: 0.0203 - precision: 0.9288 - recall: 0.8919 - val_binary_accuracy: 0.9489 - val_f1__macro: 0.2794 - val_loss: 0.3426 - val_precision: 0.3851 - val_recall: 0.3649\n",
      "Epoch 22/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 18ms/step - binary_accuracy: 0.9928 - f1__macro: 0.8395 - loss: 0.0197 - precision: 0.9306 - recall: 0.8965 - val_binary_accuracy: 0.9472 - val_f1__macro: 0.2712 - val_loss: 0.3552 - val_precision: 0.3680 - val_recall: 0.3589\n",
      "Epoch 23/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - binary_accuracy: 0.9928 - f1__macro: 0.8435 - loss: 0.0199 - precision: 0.9311 - recall: 0.8953 - val_binary_accuracy: 0.9473 - val_f1__macro: 0.2798 - val_loss: 0.3678 - val_precision: 0.3696 - val_recall: 0.3607\n",
      "Epoch 24/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - binary_accuracy: 0.9929 - f1__macro: 0.8423 - loss: 0.0194 - precision: 0.9309 - recall: 0.8983 - val_binary_accuracy: 0.9462 - val_f1__macro: 0.2694 - val_loss: 0.3749 - val_precision: 0.3606 - val_recall: 0.3632\n",
      "Epoch 25/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - binary_accuracy: 0.9933 - f1__macro: 0.8515 - loss: 0.0188 - precision: 0.9347 - recall: 0.9044 - val_binary_accuracy: 0.9483 - val_f1__macro: 0.2702 - val_loss: 0.3821 - val_precision: 0.3790 - val_recall: 0.3624\n",
      "Epoch 26/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - binary_accuracy: 0.9931 - f1__macro: 0.8518 - loss: 0.0189 - precision: 0.9322 - recall: 0.9021 - val_binary_accuracy: 0.9462 - val_f1__macro: 0.2644 - val_loss: 0.4006 - val_precision: 0.3650 - val_recall: 0.3803\n",
      "Epoch 27/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - binary_accuracy: 0.9933 - f1__macro: 0.8553 - loss: 0.0184 - precision: 0.9342 - recall: 0.9033 - val_binary_accuracy: 0.9459 - val_f1__macro: 0.2735 - val_loss: 0.4007 - val_precision: 0.3607 - val_recall: 0.3718\n",
      "Epoch 28/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - binary_accuracy: 0.9935 - f1__macro: 0.8577 - loss: 0.0179 - precision: 0.9360 - recall: 0.9071 - val_binary_accuracy: 0.9461 - val_f1__macro: 0.2632 - val_loss: 0.4097 - val_precision: 0.3663 - val_recall: 0.3892\n",
      "Epoch 29/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 18ms/step - binary_accuracy: 0.9935 - f1__macro: 0.8608 - loss: 0.0178 - precision: 0.9358 - recall: 0.9071 - val_binary_accuracy: 0.9456 - val_f1__macro: 0.2657 - val_loss: 0.4281 - val_precision: 0.3538 - val_recall: 0.3564\n",
      "Epoch 30/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 18ms/step - binary_accuracy: 0.9937 - f1__macro: 0.8550 - loss: 0.0172 - precision: 0.9360 - recall: 0.9121 - val_binary_accuracy: 0.9448 - val_f1__macro: 0.2653 - val_loss: 0.4270 - val_precision: 0.3542 - val_recall: 0.3818\n",
      "Epoch 31/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 19ms/step - binary_accuracy: 0.9937 - f1__macro: 0.8615 - loss: 0.0173 - precision: 0.9368 - recall: 0.9115 - val_binary_accuracy: 0.9458 - val_f1__macro: 0.2589 - val_loss: 0.4424 - val_precision: 0.3582 - val_recall: 0.3658\n",
      "Epoch 32/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 18ms/step - binary_accuracy: 0.9936 - f1__macro: 0.8598 - loss: 0.0175 - precision: 0.9351 - recall: 0.9108 - val_binary_accuracy: 0.9433 - val_f1__macro: 0.2651 - val_loss: 0.4475 - val_precision: 0.3400 - val_recall: 0.3712\n",
      "Epoch 33/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - binary_accuracy: 0.9937 - f1__macro: 0.8627 - loss: 0.0171 - precision: 0.9382 - recall: 0.9116 - val_binary_accuracy: 0.9452 - val_f1__macro: 0.2644 - val_loss: 0.4569 - val_precision: 0.3547 - val_recall: 0.3718\n",
      "Epoch 34/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - binary_accuracy: 0.9937 - f1__macro: 0.8556 - loss: 0.0169 - precision: 0.9371 - recall: 0.9114 - val_binary_accuracy: 0.9445 - val_f1__macro: 0.2734 - val_loss: 0.4630 - val_precision: 0.3477 - val_recall: 0.3677\n",
      "Epoch 35/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 19ms/step - binary_accuracy: 0.9940 - f1__macro: 0.8614 - loss: 0.0164 - precision: 0.9390 - recall: 0.9160 - val_binary_accuracy: 0.9449 - val_f1__macro: 0.2625 - val_loss: 0.4720 - val_precision: 0.3515 - val_recall: 0.3690\n",
      "Epoch 36/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - binary_accuracy: 0.9939 - f1__macro: 0.8576 - loss: 0.0168 - precision: 0.9390 - recall: 0.9137 - val_binary_accuracy: 0.9444 - val_f1__macro: 0.2552 - val_loss: 0.4815 - val_precision: 0.3461 - val_recall: 0.3639\n",
      "Epoch 37/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 19ms/step - binary_accuracy: 0.9941 - f1__macro: 0.8679 - loss: 0.0165 - precision: 0.9409 - recall: 0.9177 - val_binary_accuracy: 0.9434 - val_f1__macro: 0.2629 - val_loss: 0.4895 - val_precision: 0.3442 - val_recall: 0.3837\n",
      "Epoch 38/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - binary_accuracy: 0.9941 - f1__macro: 0.8661 - loss: 0.0162 - precision: 0.9390 - recall: 0.9188 - val_binary_accuracy: 0.9436 - val_f1__macro: 0.2576 - val_loss: 0.4906 - val_precision: 0.3452 - val_recall: 0.3817\n",
      "Epoch 39/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 19ms/step - binary_accuracy: 0.9942 - f1__macro: 0.8682 - loss: 0.0159 - precision: 0.9422 - recall: 0.9192 - val_binary_accuracy: 0.9434 - val_f1__macro: 0.2607 - val_loss: 0.4998 - val_precision: 0.3395 - val_recall: 0.3672\n",
      "Epoch 40/40\n",
      "\u001b[1m1357/1357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - binary_accuracy: 0.9942 - f1__macro: 0.8700 - loss: 0.0159 - precision: 0.9423 - recall: 0.9191 - val_binary_accuracy: 0.9449 - val_f1__macro: 0.2561 - val_loss: 0.5036 - val_precision: 0.3469 - val_recall: 0.3531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3146869d0>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = classification_metrics(\"macro\")\n",
    "mlp.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=\"adam\",\n",
    "        metrics=metrics\n",
    "    )\n",
    "\n",
    "mlp.fit(X_train_int, y_train_int, epochs=40, validation_data=(X_dev_int, y_dev_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev_pred = clf.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - binary_accuracy: 0.9457 - f1__macro: 0.2639 - loss: 0.4909 - precision: 0.3510 - recall: 0.3573\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4936329424381256,\n",
       " 0.265544056892395,\n",
       " 0.9453725814819336,\n",
       " 0.347980260848999,\n",
       " 0.3566124141216278]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.evaluate(X_test_int, y_test_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.37      0.49       488\n",
      "           1       0.79      0.41      0.54       303\n",
      "           2       0.60      0.19      0.29       195\n",
      "           3       0.17      0.01      0.01       303\n",
      "           4       0.65      0.06      0.10       397\n",
      "           5       0.50      0.01      0.03       153\n",
      "           6       0.71      0.08      0.14       152\n",
      "           7       0.59      0.09      0.16       248\n",
      "           8       0.76      0.29      0.42        77\n",
      "           9       0.50      0.01      0.01       163\n",
      "          10       0.20      0.01      0.02       292\n",
      "          11       0.44      0.12      0.19        97\n",
      "          12       0.50      0.03      0.05        35\n",
      "          13       0.28      0.05      0.09        96\n",
      "          14       0.73      0.12      0.21        90\n",
      "          15       0.97      0.78      0.86       358\n",
      "          16       0.00      0.00      0.00        13\n",
      "          17       0.59      0.20      0.30       172\n",
      "          18       0.76      0.70      0.73       252\n",
      "          19       0.00      0.00      0.00        21\n",
      "          20       0.76      0.30      0.43       209\n",
      "          21       1.00      0.13      0.24        15\n",
      "          22       0.67      0.02      0.03       127\n",
      "          23       0.00      0.00      0.00        18\n",
      "          24       0.79      0.28      0.41        68\n",
      "          25       0.60      0.17      0.26       143\n",
      "          26       0.58      0.14      0.23       129\n",
      "          27       0.56      0.55      0.56      1766\n",
      "\n",
      "   micro avg       0.65      0.32      0.43      6380\n",
      "   macro avg       0.55      0.18      0.24      6380\n",
      "weighted avg       0.60      0.32      0.37      6380\n",
      " samples avg       0.37      0.35      0.35      6380\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haiduong/miniforge3/envs/emotiai/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/haiduong/miniforge3/envs/emotiai/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, y_dev_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emotiai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
