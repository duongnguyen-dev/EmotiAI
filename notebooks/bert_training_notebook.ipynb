{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check available GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_USE_LEGACY_KERAS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "import h5py\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text\n",
    "import numpy as np\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "from skmultilearn.model_selection.iterative_stratification import IterativeStratification\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertConfig:\n",
    "    BERT_PREPROCESSOR=\"https://kaggle.com/models/tensorflow/bert/TensorFlow2/en-uncased-preprocess/3\"\n",
    "    BERT_MODEL=\"https://www.kaggle.com/models/tensorflow/bert/TensorFlow2/bert-en-uncased-l-12-h-768-a-12/2\"\n",
    "    SEQUENCE_LENGTH=13\n",
    "    BATCH_SIZE=16\n",
    "    EPOCHS=3\n",
    "    LR=2e-5\n",
    "    NUM_CLASSES=28\n",
    "    SHUFFLE=42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ds(dataset_type: str, key: str, secret: str, endpoint_url: str):\n",
    "    s3 = s3fs.S3FileSystem(\n",
    "        anon=False, \n",
    "        key=key, \n",
    "        secret=secret, \n",
    "        endpoint_url=endpoint_url\n",
    "    )\n",
    "\n",
    "    with s3.open(f's3://emotiai/goemotion/{dataset_type}.h5', 'rb') as f:\n",
    "        h5_file = h5py.File(f, 'r')\n",
    "\n",
    "        # Stack all tensors into a single tensor (if they have the same shape)\n",
    "        features = h5_file[\"features\"]\n",
    "        tensored_features = tf.convert_to_tensor(features)\n",
    "\n",
    "        labels = h5_file['labels']\n",
    "        tensored_labels = tf.convert_to_tensor(labels[:], dtype=tf.float32)  \n",
    "        \n",
    "    return tf.data.Dataset.from_tensor_slices((tensored_features, tensored_labels)).shuffle(BertConfig.SHUFFLE).batch(BertConfig.BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ds_10_percent(dataset_type: str, key: str, secret: str, endpoint_url: str, split_size=0.1):\n",
    "    s3 = s3fs.S3FileSystem(\n",
    "        anon=False, \n",
    "        key=key, \n",
    "        secret=secret, \n",
    "        endpoint_url=endpoint_url\n",
    "    )\n",
    "\n",
    "    with s3.open(f's3://emotiai/goemotion/{dataset_type}.h5', 'rb') as f:\n",
    "        h5_file = h5py.File(f, 'r')\n",
    "\n",
    "        features = np.array(h5_file[\"features\"]).reshape(-1, 1)\n",
    "        labels = np.array(h5_file['labels'][:])\n",
    "        \n",
    "        _, _, X_subset, y_subset = iterative_train_test_split(features, labels, test_size=split_size)\n",
    "        \n",
    "        tensored_features = tf.convert_to_tensor(X_subset)\n",
    "        tensored_labels = tf.convert_to_tensor(y_subset, dtype=tf.float32)\n",
    "\n",
    "    return tf.data.Dataset.from_tensor_slices((tensored_features, tensored_labels)).shuffle(BertConfig.SHUFFLE).batch(BertConfig.BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_KEY=\"minio_access_key\"\n",
    "SECRET_KEY=\"minio_secret_key\"\n",
    "ENDPOINT_URL=\"http://localhost:9000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 10:02:56.290701: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2025-03-25 10:02:56.290723: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-03-25 10:02:56.290728: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1742871776.292262 12582399 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1742871776.292691 12582399 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "train_ds = load_ds(\"train\", key=ACCESS_KEY, secret=SECRET_KEY, endpoint_url=ENDPOINT_URL)\n",
    "dev_ds = load_ds(\"dev\", key=ACCESS_KEY, secret=SECRET_KEY, endpoint_url=ENDPOINT_URL)\n",
    "test_ds = load_ds(\"test\", key=ACCESS_KEY, secret=SECRET_KEY, endpoint_url=ENDPOINT_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bert_preprocessor():\n",
    "    preprocessor = hub.load(BertConfig.BERT_PREPROCESSOR)\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "    tokenize = hub.KerasLayer(preprocessor.tokenize)\n",
    "    tokenized_input = tokenize(text_input)\n",
    "    packer = hub.KerasLayer(\n",
    "        preprocessor.bert_pack_inputs,\n",
    "        arguments=dict(seq_length=BertConfig.SEQUENCE_LENGTH)\n",
    "    )\n",
    "    encoder_inputs = packer([tokenized_input])\n",
    "\n",
    "    return tf.keras.Model(text_input, encoder_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bert_model(bert_preprocessor, bert_model):\n",
    "    inputs = tf.keras.layers.Input(shape=(), dtype=\"string\")\n",
    "    encoder_inputs = bert_preprocessor(inputs)\n",
    "    bert_outputs = bert_model(encoder_inputs)\n",
    "    outputs = tf.keras.layers.Dense(BertConfig.NUM_CLASSES, activation=\"sigmoid\")(bert_outputs[\"pooled_output\"])\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_metrics(average: str = None):\n",
    "    f1_name = f'_{average}'\n",
    "    if average == None:\n",
    "        f1_name = ''\n",
    "\n",
    "    return [tf.keras.metrics.F1Score(\n",
    "        name=f'f1_{f1_name}',\n",
    "        average=average,\n",
    "    ), tf.keras.metrics.BinaryAccuracy(\"binary_accuracy\"), tf.keras.metrics.Precision(name=\"precision\"), tf.keras.metrics.Recall(name=\"recall\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning \n",
    "- Feature extraction on 10% of the training dataset\n",
    "- Fine-tuning with all freeze layer\n",
    "- Fine-tuning without freezing bottom layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_80_percent = load_ds_10_percent(\"train\", key=ACCESS_KEY, secret=SECRET_KEY, endpoint_url=ENDPOINT_URL, split_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 10:03:48.990048: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2171/2171 [==============================] - 1833s 837ms/step - loss: 0.1186 - f1__macro: 0.2685 - binary_accuracy: 0.9625 - precision: 0.6286 - recall: 0.2653 - val_loss: 0.1009 - val_f1__macro: 0.3631 - val_binary_accuracy: 0.9667 - val_precision: 0.6883 - val_recall: 0.3804\n",
      "Epoch 2/3\n",
      "2171/2171 [==============================] - 1817s 837ms/step - loss: 0.0957 - f1__macro: 0.4016 - binary_accuracy: 0.9682 - precision: 0.7148 - recall: 0.4047 - val_loss: 0.0992 - val_f1__macro: 0.4064 - val_binary_accuracy: 0.9666 - val_precision: 0.6622 - val_recall: 0.4166\n",
      "Epoch 3/3\n",
      "2171/2171 [==============================] - 1797s 828ms/step - loss: 0.0833 - f1__macro: 0.4817 - binary_accuracy: 0.9719 - precision: 0.7566 - recall: 0.4877 - val_loss: 0.1047 - val_f1__macro: 0.4107 - val_binary_accuracy: 0.9651 - val_precision: 0.6232 - val_recall: 0.4290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x3561622d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine tuning unfreeze on all train dataset\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "metrics = classification_metrics(\"macro\")\n",
    "bert_preprocessor = build_bert_preprocessor()\n",
    "bert_model = hub.KerasLayer(BertConfig.BERT_MODEL, trainable=True)\n",
    "\n",
    "model = build_bert_model(bert_preprocessor, bert_model)\n",
    "\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=BertConfig.LR),\n",
    "    metrics=metrics\n",
    ")\n",
    "model.fit(train_ds_80_percent, epochs=BertConfig.EPOCHS, validation_data=dev_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742815497.701410 12079929 meta_optimizer.cc:966] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2714/2714 [==============================] - 1398s 510ms/step - loss: 0.1889 - f1__macro: 0.0244 - binary_accuracy: 0.9433 - precision: 0.0816 - recall: 0.0340 - val_loss: 0.1469 - val_f1__macro: 0.0343 - val_binary_accuracy: 0.9581 - val_precision: 0.5283 - val_recall: 0.0307\n",
      "Epoch 2/4\n",
      "2714/2714 [==============================] - 1455s 536ms/step - loss: 0.1427 - f1__macro: 0.0442 - binary_accuracy: 0.9583 - precision: 0.5641 - recall: 0.0395 - val_loss: 0.1391 - val_f1__macro: 0.0546 - val_binary_accuracy: 0.9584 - val_precision: 0.5568 - val_recall: 0.0484\n",
      "Epoch 3/4\n",
      "2714/2714 [==============================] - 1409s 519ms/step - loss: 0.1372 - f1__macro: 0.0619 - binary_accuracy: 0.9587 - precision: 0.5953 - recall: 0.0574 - val_loss: 0.1351 - val_f1__macro: 0.0727 - val_binary_accuracy: 0.9588 - val_precision: 0.5845 - val_recall: 0.0639\n",
      "Epoch 4/4\n",
      "2714/2714 [==============================] - 1177s 434ms/step - loss: 0.1340 - f1__macro: 0.0763 - binary_accuracy: 0.9591 - precision: 0.6128 - recall: 0.0712 - val_loss: 0.1325 - val_f1__macro: 0.0874 - val_binary_accuracy: 0.9590 - val_precision: 0.5961 - val_recall: 0.0768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x31aa42250>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Fine-tuning with all freeze layer\n",
    "\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# metrics = classification_metrics(\"macro\")\n",
    "# bert_preprocessor = build_bert_preprocessor()\n",
    "# bert_model = hub.KerasLayer(BertConfig.BERT_MODEL, trainable=False)\n",
    "\n",
    "# model = build_bert_model(bert_preprocessor, bert_model)\n",
    "\n",
    "# model.compile(\n",
    "#     loss=\"binary_crossentropy\",\n",
    "#     optimizer=tf.keras.optimizers.Adam(learning_rate=BertConfig.LR),\n",
    "#     metrics=metrics\n",
    "# )\n",
    "# model.fit(train_ds, epochs=BertConfig.EPOCHS, validation_data=dev_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model):\n",
    "    y_pred = model.predict(test_ds)\n",
    "    \n",
    "    threshold = 0.5\n",
    "    y_pred = (y_pred >= threshold).astype(int)\n",
    "    y_true = np.array([label.numpy() for _, label in test_ds.unbatch()])\n",
    "    \n",
    "    precision_per_class = precision_score(y_true, y_pred, average=None)\n",
    "    recall_per_class = recall_score(y_true, y_pred, average=None)\n",
    "    f1_per_class = f1_score(y_true, y_pred, average=None)\n",
    "    classnames = [\n",
    "        \"admiration\",\n",
    "        \"amusement\",\n",
    "        \"anger\",\n",
    "        \"annoyance\",\n",
    "        \"approval\",\n",
    "        \"caring\",\n",
    "        \"confusion\",\n",
    "        \"curiosity\",\n",
    "        \"desire\",\n",
    "        \"disappointment\",\n",
    "        \"disapproval\",\n",
    "        \"disgust\",\n",
    "        \"embarrassment\",\n",
    "        \"excitement\",\n",
    "        \"fear\",\n",
    "        \"gratitude\",\n",
    "        \"grief\",\n",
    "        \"joy\",\n",
    "        \"love\",\n",
    "        \"nervousness\",\n",
    "        \"optimism\",\n",
    "        \"pride\",\n",
    "        \"realization\",\n",
    "        \"relief\",\n",
    "        \"remorse\",\n",
    "        \"sadness\",\n",
    "        \"surprise\",\n",
    "        \"neutral\"\n",
    "    ]\n",
    "\n",
    "\n",
    "    for i in range(BertConfig.NUM_CLASSES):\n",
    "        print(f\"Class {classnames[i]}:\")\n",
    "        print(f\"  Precision: {precision_per_class[i]:.4f}\")\n",
    "        print(f\"  Recall:    {recall_per_class[i]:.4f}\")\n",
    "        print(f\"  F1-Score:  {f1_per_class[i]:.4f}\")\n",
    "    \n",
    "    print(f\"  Precision macro-average: {precision_per_class[i]:.4f}\")\n",
    "    print(f\"  Recall macro-average:    {recall_per_class[i]:.4f}\")\n",
    "    print(f\"  F1-Score macro-average:  {f1_per_class[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340/340 [==============================] - 111s 314ms/step\n",
      "Class admiration:\n",
      "  Precision: 0.0935\n",
      "  Recall:    0.0575\n",
      "  F1-Score:  0.0713\n",
      "Class amusement:\n",
      "  Precision: 0.0667\n",
      "  Recall:    0.0606\n",
      "  F1-Score:  0.0635\n",
      "Class anger:\n",
      "  Precision: 0.0532\n",
      "  Recall:    0.0505\n",
      "  F1-Score:  0.0518\n",
      "Class annoyance:\n",
      "  Precision: 0.0598\n",
      "  Recall:    0.0219\n",
      "  F1-Score:  0.0320\n",
      "Class approval:\n",
      "  Precision: 0.1148\n",
      "  Recall:    0.0399\n",
      "  F1-Score:  0.0592\n",
      "Class caring:\n",
      "  Precision: 0.0172\n",
      "  Recall:    0.0074\n",
      "  F1-Score:  0.0104\n",
      "Class confusion:\n",
      "  Precision: 0.0405\n",
      "  Recall:    0.0196\n",
      "  F1-Score:  0.0264\n",
      "Class curiosity:\n",
      "  Precision: 0.0468\n",
      "  Recall:    0.0387\n",
      "  F1-Score:  0.0424\n",
      "Class desire:\n",
      "  Precision: 0.0333\n",
      "  Recall:    0.0120\n",
      "  F1-Score:  0.0177\n",
      "Class disappointment:\n",
      "  Precision: 0.0357\n",
      "  Recall:    0.0066\n",
      "  F1-Score:  0.0112\n",
      "Class disapproval:\n",
      "  Precision: 0.0159\n",
      "  Recall:    0.0075\n",
      "  F1-Score:  0.0102\n",
      "Class disgust:\n",
      "  Precision: 0.0292\n",
      "  Recall:    0.0325\n",
      "  F1-Score:  0.0308\n",
      "Class embarrassment:\n",
      "  Precision: 0.0000\n",
      "  Recall:    0.0000\n",
      "  F1-Score:  0.0000\n",
      "Class excitement:\n",
      "  Precision: 0.0000\n",
      "  Recall:    0.0000\n",
      "  F1-Score:  0.0000\n",
      "Class fear:\n",
      "  Precision: 0.0222\n",
      "  Recall:    0.0128\n",
      "  F1-Score:  0.0163\n",
      "Class gratitude:\n",
      "  Precision: 0.0878\n",
      "  Recall:    0.0739\n",
      "  F1-Score:  0.0802\n",
      "Class grief:\n",
      "  Precision: 0.0000\n",
      "  Recall:    0.0000\n",
      "  F1-Score:  0.0000\n",
      "Class joy:\n",
      "  Precision: 0.0455\n",
      "  Recall:    0.0373\n",
      "  F1-Score:  0.0410\n",
      "Class love:\n",
      "  Precision: 0.0541\n",
      "  Recall:    0.0504\n",
      "  F1-Score:  0.0522\n",
      "Class nervousness:\n",
      "  Precision: 0.0000\n",
      "  Recall:    0.0000\n",
      "  F1-Score:  0.0000\n",
      "Class optimism:\n",
      "  Precision: 0.0093\n",
      "  Recall:    0.0054\n",
      "  F1-Score:  0.0068\n",
      "Class pride:\n",
      "  Precision: 0.0000\n",
      "  Recall:    0.0000\n",
      "  F1-Score:  0.0000\n",
      "Class realization:\n",
      "  Precision: 0.0200\n",
      "  Recall:    0.0069\n",
      "  F1-Score:  0.0103\n",
      "Class relief:\n",
      "  Precision: 0.0000\n",
      "  Recall:    0.0000\n",
      "  F1-Score:  0.0000\n",
      "Class remorse:\n",
      "  Precision: 0.0000\n",
      "  Recall:    0.0000\n",
      "  F1-Score:  0.0000\n",
      "Class sadness:\n",
      "  Precision: 0.0110\n",
      "  Recall:    0.0064\n",
      "  F1-Score:  0.0081\n",
      "Class surprise:\n",
      "  Precision: 0.0204\n",
      "  Recall:    0.0142\n",
      "  F1-Score:  0.0167\n",
      "Class neutral:\n",
      "  Precision: 0.3454\n",
      "  Recall:    0.2932\n",
      "  F1-Score:  0.3172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 11:37:53.664962: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "/Users/haiduong/miniforge3/envs/emotiai/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "evaluation(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emotiai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
